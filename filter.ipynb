{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the filtering function (as described in section 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#this function will do the  filtering\n",
    "def filter_spikes(alldata, session_id):\n",
    "    #alldata is the collated data from all sessions/neurons/timepoints as shown in the tutorial notebook\n",
    "    #grab spikes/choices from one section\n",
    "    dat = alldat[session_id]\n",
    "    spks = dat['spks']\n",
    "    chcs = dat['response']\n",
    "    \n",
    "    #grab only spikes/choices from trials where left/right contrast is equal and nonzero\n",
    "    unfair_filter = np.logical_and(np.equal(dat['contrast_right'],dat['contrast_left']), (dat['contrast_right'] != 0))\n",
    "    unfair_chosey_filter = np.logical_and(unfair_filter,(dat['response']!=0))\n",
    "    spks = spks[:,unfair_chosey_filter,:]\n",
    "    chcs = chcs[unfair_chosey_filter]\n",
    "    \n",
    "    #grab only spikes from the VISp\n",
    "    spks = spks[dat['brain_area']=='VISp',:,:]\n",
    "    \n",
    "    #grab only spikes from between -500ms and 500ms, relative to stimulus onset (each bin is 10ms)\n",
    "    spks = spks[:,:,0:100]\n",
    "    \n",
    "    return spks, chcs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are grabbing the data and testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data retrieval\n",
    "import os, requests\n",
    "import numpy as np\n",
    "\n",
    "fname = []\n",
    "for j in range(3):\n",
    "  fname.append('steinmetz_part%d.npz'%j)\n",
    "url = [\"https://osf.io/agvxh/download\"]\n",
    "url.append(\"https://osf.io/uv3mw/download\")\n",
    "url.append(\"https://osf.io/ehmw2/download\")\n",
    "\n",
    "for j in range(len(url)):\n",
    "  if not os.path.isfile(fname[j]):\n",
    "    try:\n",
    "      r = requests.get(url[j])\n",
    "    except requests.ConnectionError:\n",
    "      print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "      if r.status_code != requests.codes.ok:\n",
    "        print(\"!!! Failed to download data !!!\")\n",
    "      else:\n",
    "        with open(fname[j], \"wb\") as fid:\n",
    "          fid.write(r.content)\n",
    "        \n",
    "#@title Data loading\n",
    "import numpy as np\n",
    "\n",
    "alldat = np.array([])\n",
    "for j in range(len(fname)):\n",
    "  alldat = np.hstack((alldat, np.load('steinmetz_part%d.npz'%j, allow_pickle=True)['dat']))\n",
    "\n",
    "# select just one of the recordings here. 11 is nice because it has some neurons in vis ctx. \n",
    "dat = alldat[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 18, 100) (18,)\n"
     ]
    }
   ],
   "source": [
    "#Test fucntion\n",
    "spks_filtered, chcs_filtered = filter_spikes(alldat,11)\n",
    "\n",
    "#The shape of spks is neuron x trial x time point (-500 to 500)\n",
    "#The shape of choices is by trial\n",
    "print(spks_filtered.shape, chcs_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
